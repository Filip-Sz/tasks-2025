{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models\n",
    "from typing import Tuple\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 1\n",
    "MEMBERSHIP_DATASET_PATH = \"data/priv_out.pt\"       # Path to priv_out_.pt\n",
    "MIA_CKPT_PATH = \"data/01_MIA_69.pt\"                 # Path to 01_MIA_69.pt\n",
    "PUB_DATASET_PATH = \"data/pub.pt\"              # Path to pub.pt\n",
    "\n",
    "\n",
    "allowed_models = {\n",
    "    \"resnet18\": models.resnet18,\n",
    "    \"resnet34\": models.resnet34,\n",
    "    \"resnet50\": models.resnet50,\n",
    "}\n",
    "\n",
    "\n",
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if not self.transform is None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "\n",
    "class MembershipDataset(TaskDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__(transform)\n",
    "        self.membership = []\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int, int]:\n",
    "        id_, img, label = super().__getitem__(index)\n",
    "        return id_, img, label, self.membership[index]\n",
    "\n",
    "def get_dataset(dataset_path):\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    MEAN = [0.2980, 0.2962, 0.2987]\n",
    "    STD = [0.2886, 0.2875, 0.2889]\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Normalize(mean=MEAN, std=STD)  # Apply normalization\n",
    "    ])\n",
    "\n",
    "    with torch.serialization.safe_globals([MembershipDataset]):\n",
    "        dataset: MembershipDataset = torch.load(dataset_path)\n",
    "        dataset.transform = transform\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "            if dataset.membership[i] is None:\n",
    "                dataset.membership[i] = 0\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "def inference_dataloader(dataset: MembershipDataset, batch_size):\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset, batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "def load_model(model_name, model_path):\n",
    "    try:\n",
    "        model: nn.Module = allowed_models[model_name](weights=None)\n",
    "        model.fc = nn.Linear(model.fc.weight.shape[1], 44)\n",
    "    except Exception as e:\n",
    "        raise Exception(\n",
    "            f\"Invalid model class, {e}, only {allowed_models.keys()} are allowed\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        model_state_dict = torch.load(model_path, map_location=DEVICE, weights_only=False)\n",
    "        model.load_state_dict(model_state_dict, strict=True)\n",
    "        model.eval()\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Invalid model, {e}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_loss_value(model, img, label):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    output = model(img)\n",
    "    loss = criterion(output, label)\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_value(model, img, label):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    output = model(img)\n",
    "    loss = criterion(output, label)\n",
    "    return loss.item()\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "class MembershipScoreCalculation:\n",
    "    def __init__(self, in_losses, out_losses, prior_in=0.5, prior_out=0.5):\n",
    "            # Convert inputs to numpy arrays and apply transformations\n",
    "            in_losses = self.apply_transformations(np.array(in_losses))\n",
    "            out_losses = self.apply_transformations(np.array(out_losses))\n",
    "\n",
    "            # Check if we have enough data for KDE\n",
    "            if in_losses.size <= 1 or out_losses.size <= 1:\n",
    "                self.use_kde = False\n",
    "                self.kde_in = self.kde_out = None  # No KDE available\n",
    "                self.in_mean = in_losses.mean() if in_losses.size > 0 else 0.0\n",
    "                self.out_mean = out_losses.mean() if out_losses.size > 0 else 0.0\n",
    "            else:\n",
    "                self.use_kde = True\n",
    "                self.kde_in = gaussian_kde(in_losses)\n",
    "                self.kde_out = gaussian_kde(out_losses)\n",
    "\n",
    "            self.prior_in = prior_in\n",
    "            self.prior_out = prior_out\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_transformations(loss):\n",
    "        # check if any of loss values is nan\n",
    "        loss = np.exp(-loss)\n",
    "        eps = 1e-9  \n",
    "        loss = np.clip(loss, eps, 1 - eps)\n",
    "        loss = np.log(loss / (1 - loss))\n",
    "        return loss\n",
    "    \n",
    "    def get_score(self, loss: float) -> float:\n",
    "        \"\"\"\n",
    "        Oblicza prawdopodobieństwo, że loss pochodzi z \"in\".\n",
    "        :param loss: Wartość loss do oceny.\n",
    "        :return: Prawdopodobieństwo przynależności do \"in\" w zakresie [0, 1].\n",
    "        \"\"\"\n",
    "        loss = self.apply_transformations(loss)\n",
    "        \n",
    "        if not self.use_kde:\n",
    "            if hasattr(self, 'in_mean') and hasattr(self, 'out_mean'):\n",
    "                    midpoint = (self.in_mean + self.out_mean) / 2 if self.in_mean != self.out_mean else 0.0\n",
    "                    score = 1 / (1 + np.exp(loss - midpoint))  # Sigmoid function\n",
    "                    return float(np.clip(score, 0, 1))\n",
    "            else:\n",
    "                # If no data at all, map transformed_loss to [0, 1] directly\n",
    "                score = 1 / (1 + np.exp(loss))  # Sigmoid without reference point\n",
    "                return float(np.clip(score, 0, 1))\n",
    "\n",
    "        p_in = self.kde_in(loss) * self.prior_in\n",
    "        p_out = self.kde_out(loss) * self.prior_out\n",
    "        \n",
    "        if p_in + p_out == 0:\n",
    "            return 0.5 \n",
    "        \n",
    "        res = p_in / (p_in + p_out)\n",
    "        return res[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid model, PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 88\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, model_path)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     model_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/net/tscratch/people/tutorial044/venv/lib64/python3.9/site-packages/torch/serialization.py:1432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1431\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1432\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n",
      "File \u001b[0;32m/net/tscratch/people/tutorial044/venv/lib64/python3.9/site-packages/torch/serialization.py:763\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIA_CKPT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m class_losses_in \u001b[38;5;241m=\u001b[39m {c: [] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m44\u001b[39m)}\n\u001b[1;32m      5\u001b[0m class_losses_out \u001b[38;5;241m=\u001b[39m {c: [] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m44\u001b[39m)}\n",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, model_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mException\u001b[0m: Invalid model, PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load_model(model_name=\"resnet18\", model_path=MIA_CKPT_PATH)\n",
    "\n",
    "\n",
    "class_losses_in = {c: [] for c in range(44)}\n",
    "class_losses_out = {c: [] for c in range(44)}\n",
    "\n",
    "dataset_pub = get_dataset(PUB_DATASET_PATH)\n",
    "dataloader_pub = inference_dataloader(dataset_pub, BATCH_SIZE)\n",
    "\n",
    "for id_, img, label, membership in tqdm(dataloader_pub):\n",
    "    loss = get_loss_value(model, img, label)\n",
    "    if membership == 1:\n",
    "        class_losses_in[label.item()].append(loss)\n",
    "    else:\n",
    "        class_losses_out[label.item()].append(loss)\n",
    "\n",
    "class_scorers = dict()\n",
    "for i in range(44):\n",
    "    print(f\"Class {i}\")\n",
    "    class_scorers[i] = MembershipScoreCalculation(class_losses_in[i], class_losses_out[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Invalid model, PytorchStreamReader failed reading zip archive: failed finding central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 88\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, model_path)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     model_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(model_state_dict, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/net/tscratch/people/tutorial044/venv/lib64/python3.9/site-packages/torch/serialization.py:1432\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1431\u001b[0m overall_storage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1432\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_file\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m   1433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_torchscript_zip(opened_zipfile):\n",
      "File \u001b[0;32m/net/tscratch/people/tutorial044/venv/lib64/python3.9/site-packages/torch/serialization.py:763\u001b[0m, in \u001b[0;36m_open_zipfile_reader.__init__\u001b[0;34m(self, name_or_buffer)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name_or_buffer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: PytorchStreamReader failed reading zip archive: failed finding central directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m     17\u001b[0m         {\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m: dataset\u001b[38;5;241m.\u001b[39mids,\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: outputs_list,\n\u001b[1;32m     20\u001b[0m         }\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet18\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIA_CKPT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     preds \u001b[38;5;241m=\u001b[39m membership_prediction(model, MEMBERSHIP_DATASET_PATH)\n\u001b[1;32m     27\u001b[0m     preds\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/pub_submission.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 92\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_name, model_path)\u001b[0m\n\u001b[1;32m     90\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid model, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mException\u001b[0m: Invalid model, PytorchStreamReader failed reading zip archive: failed finding central directory"
     ]
    }
   ],
   "source": [
    "def membership_prediction(model, dataset_path):\n",
    "    dataloader = inference_dataloader(get_dataset(dataset_path), BATCH_SIZE)\n",
    "\n",
    "    outputs_list = []\n",
    "\n",
    "    for _, img, label, _ in tqdm(dataloader):\n",
    "        img = img.to(DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss = get_loss_value(model, img, label)\n",
    "        \n",
    "        membership_score = [class_scorers[label.item()].get_score(loss)]\n",
    "\n",
    "        outputs_list += membership_score\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"ids\": dataset.ids,\n",
    "            \"score\": outputs_list,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = load_model(model_name=\"resnet18\", model_path=MIA_CKPT_PATH)\n",
    "    preds = membership_prediction(model, MEMBERSHIP_DATASET_PATH)\n",
    "    preds.to_csv(\"data/pub_submission.csv\", index=False)\n",
    "\n",
    "    print(\"Outputs saved to pub_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = requests.post(\n",
    "    URL,\n",
    "    headers={\"token\": TOKEN},\n",
    "    files={\n",
    "        \"csv_file\": (\"submission.csv\", open(\"./submission.csv\", \"rb\"))\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result.status_code, result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0\n",
      "Class 1\n",
      "Class 2\n",
      "Class 3\n",
      "Class 4\n",
      "Class 5\n",
      "Class 6\n",
      "Class 7\n",
      "Class 8\n",
      "Class 9\n",
      "Class 10\n",
      "Class 11\n",
      "Class 12\n",
      "Class 13\n",
      "Class 14\n",
      "Class 15\n",
      "Class 16\n",
      "Class 17\n",
      "Class 18\n",
      "Class 19\n",
      "Class 20\n",
      "Class 21\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`dataset` input should have multiple elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m44\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m     class_scorers[i] \u001b[38;5;241m=\u001b[39m MembershipScoreCalculation(class_losses_in[i], class_losses_out[i])\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36mMembershipScoreCalculation.__init__\u001b[0;34m(self, in_losses, out_losses, prior_in, prior_out)\u001b[0m\n\u001b[1;32m     14\u001b[0m in_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_transformations(np\u001b[38;5;241m.\u001b[39marray(in_losses))\n\u001b[1;32m     15\u001b[0m out_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_transformations( np\u001b[38;5;241m.\u001b[39marray(out_losses))\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkde_in \u001b[38;5;241m=\u001b[39m gaussian_kde(in_losses)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkde_out \u001b[38;5;241m=\u001b[39m gaussian_kde(out_losses)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior_in \u001b[38;5;241m=\u001b[39m prior_in\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/scipy/stats/_kde.py:202\u001b[0m, in \u001b[0;36mgaussian_kde.__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m atleast_2d(asarray(dataset))\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`dataset` input should have multiple elements.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: `dataset` input should have multiple elements."
     ]
    }
   ],
   "source": [
    "class_scorers = dict()\n",
    "for i in range(44):\n",
    "    print(f\"Class {i}\")\n",
    "    class_scorers[i] = MembershipScoreCalculation(class_losses_in[i], class_losses_out[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4629805]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "class MembershipScoreCalculation:\n",
    "    def __init__(self, in_losses, out_losses, prior_in=0.5, prior_out=0.5):\n",
    "\n",
    "        in_losses = self.apply_transformations(np.array(in_losses))\n",
    "        out_losses = self.apply_transformations( np.array(out_losses))\n",
    "\n",
    "        self.kde_in = gaussian_kde(in_losses)\n",
    "        self.kde_out = gaussian_kde(out_losses)\n",
    "\n",
    "        self.prior_in = prior_in\n",
    "        self.prior_out = prior_out\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_transformations(loss):\n",
    "        # check if any of loss values is nan\n",
    "        loss = np.exp(-loss)\n",
    "        eps = 1e-9  \n",
    "        loss = np.clip(loss, eps, 1 - eps)\n",
    "        loss = np.log(loss / (1 - loss))\n",
    "        return loss\n",
    "    \n",
    "    def get_score(self, loss: float) -> float:\n",
    "        \"\"\"\n",
    "        Oblicza prawdopodobieństwo, że loss pochodzi z \"in\".\n",
    "        :param loss: Wartość loss do oceny.\n",
    "        :return: Prawdopodobieństwo przynależności do \"in\" w zakresie [0, 1].\n",
    "        \"\"\"\n",
    "        loss = self.apply_transformations(loss)\n",
    "\n",
    "        p_in = self.kde_in(loss) * self.prior_in\n",
    "        p_out = self.kde_out(loss) * self.prior_out\n",
    "        \n",
    "        if p_in + p_out == 0:\n",
    "            return 0.5 \n",
    "        \n",
    "        return p_in / (p_in + p_out)\n",
    "\n",
    "# Przykład użycia:\n",
    "in_losses = np.random.normal(3, 4, 1000)  # Symulowane straty dla \"in\"\n",
    "out_losses = np.random.normal(5.7, 4, 1000)  # Symulowane straty dla \"out\"\n",
    "\n",
    "calculator = MembershipScoreCalculation(in_losses, out_losses)\n",
    "\n",
    "loss_value = 4\n",
    "prob_in = calculator.get_score(loss_value)\n",
    "print(prob_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming label is a tensor with class indices\n",
    "num_classes = 44  # Number of classes in your dataset\n",
    "one_hot_label = F.one_hot(label, num_classes=num_classes)\n",
    "print(one_hot_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0114e-09, 1.6680e-08, 3.8089e-11, 1.0310e-10, 1.3761e-06, 8.8811e-14,\n",
      "         2.4352e-06, 9.8979e-01, 2.9824e-05, 4.0334e-13, 3.4454e-09, 7.0554e-03,\n",
      "         1.8168e-13, 6.5499e-08, 7.0310e-08, 1.4095e-07, 4.9365e-10, 1.3497e-09,\n",
      "         3.9538e-04, 6.9777e-09, 1.4155e-08, 1.7135e-10, 3.2620e-06, 1.8935e-08,\n",
      "         1.3199e-09, 2.1556e-03, 1.2281e-07, 1.1705e-10, 1.8560e-08, 1.0162e-06,\n",
      "         4.4139e-16, 6.7755e-12, 1.6703e-07, 8.4817e-05, 6.9779e-05, 4.4324e-10,\n",
      "         1.7834e-11, 4.0862e-06, 2.6119e-05, 3.8731e-06, 1.4408e-07, 6.1190e-12,\n",
      "         1.2935e-09, 3.7189e-04]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "softmax_output = F.softmax(output, dim=1)\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-15.0871, -12.2842, -18.3662, -17.3704,  -7.8714, -24.4274,  -7.3006,\n",
       "           5.6146,  -4.7953, -22.9141, -13.8614,   0.6709, -23.7117, -10.9164,\n",
       "         -10.8455, -10.1500, -15.8043, -14.7985,  -2.2108, -13.1557, -12.4483,\n",
       "         -16.8624,  -7.0083, -12.1574, -14.8208,  -0.5148, -10.2877, -17.2435,\n",
       "         -12.1774,  -8.1745, -29.7317, -20.0928,  -9.9802,  -3.7501,  -3.9453,\n",
       "         -15.9120, -19.1250,  -6.7830,  -4.9280,  -6.8366, -10.1280, -20.1947,\n",
       "         -14.8411,  -2.2720]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
